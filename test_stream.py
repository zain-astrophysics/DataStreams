# -*- coding: utf-8 -*-
"""stream_twelveData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OfNNi2v3U458ODDHK1_yJyH1lu5tYvlp
"""

import sys, time

import pyspark
from pyspark.conf import SparkConf
from pyspark.context import SparkContext
from pyspark.sql import SparkSession

from pyspark.sql.functions import explode
from pyspark.sql.functions import split
from pyspark.sql.functions import col

from pyspark.sql.functions import explode, split, col, avg, lag
from pyspark.sql.window import Window

def setLogLevel(sc, level):
    from pyspark.sql import SparkSession
    spark = SparkSession(sc)
    spark.sparkContext.setLogLevel(level)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: stream_twelvedata.py <hostname> <port>", file=sys.stderr)
        sys.exit(-1)

    print ('Argv', sys.argv)

    host = sys.argv[1]
    port = int(sys.argv[2])
    print ('host', type(host), host, 'port', type(port), port)

    sc_bak = SparkContext.getOrCreate()
    sc_bak.stop()

    time.sleep(15)
    print ('Ready to work!')

    ctx = pyspark.SparkContext(appName = "stock_data", master="local[*]")
    print ('Context', ctx)

    spark = SparkSession(ctx).builder.getOrCreate()
    sc = spark.sparkContext

    setLogLevel(sc, "WARN")

    print ('Session:', spark)
    print ('SparkContext', sc)

      # Create DataFrame representing the stream of input lines from connection to host:port
    data = spark\
        .readStream\
        .format('socket')\
        .option('host', host)\
        .option('port', port)\
        .load()



    # Split the incoming data into Date, Time, Symbol, and Price
    #stock = data.select(
    # Combine Date and Time into DateTime (casting it to timestamp)
    #(split(data.value, ' ').getItem(0) + ' ' + split(data.value, ' ').getItem(1)).alias('DateTime'),
    #split(data.value, ' ').getItem(2).alias('Symbol'),    # Symbol (AAPL, MSFT)
    #split(data.value, ' ').getItem(3).cast('float').alias('Price')  # Price as float
    #)

    stock = data.select(
    (split(data.value, ' ').getItem(0).cast('string') + ' ' + split(data.value, ' ').getItem(1).cast('string')).alias('DateTime'))
    
        
    # Convert Datetime column to a proper timestamp type (if it's not already)
    #stock = stock.withColumn('DateTime', (col('DateTime')).cast('string'))
    stock = stock.withColumn('DateTime', to_timestamp(col('DateTime'), 'yyyy-MM-dd HH:mm:ss'))
    stock.printSchema()


   aaplquery = stock\
    .writeStream\
    .outputMode('append')\
    .format('console')\
    .option('truncate', 'true')\
    .start()



    #query.awaitTermination()
    aaplquery.awaitTermination()
    
